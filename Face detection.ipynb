{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdown\n",
    "import zipfile\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "import albumentations as A\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "# from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\Project\\Filter\\.venv\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe Face Detection\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(frame_rgb)\n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            ih, iw, _ = frame.shape\n",
    "            x1, y1 = int(bboxC.xmin * iw), int(bboxC.ymin * ih)\n",
    "            x2, y2 = int((bboxC.xmin + bboxC.width) * iw), int((bboxC.ymin + bboxC.height) * ih)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filter():\n",
    "    def __init__(self, model, transform):\n",
    "        self.landmark_detect = model\n",
    "        self.transform = transform\n",
    "        self.face_detect = dlib.get_frontal_face_detector()\n",
    "        self.landmark_detect.eval()\n",
    "        \n",
    "    def landmarks_detect(self, image):\n",
    "        height, width, channels = image.shape\n",
    "        \n",
    "        image = self.transform(image=image)['image']\n",
    "        in_height, in_width, in_channel = image.shape\n",
    "        image = image.unsqueeze(0)\n",
    "        landmarks = self.landmark_detect(image)\n",
    "        landmarks = landmarks.detach().numpy()\n",
    "        landmarks = landmarks.reshape(68, 2)\n",
    "        \n",
    "        # convert to 0-224 axis\n",
    "        landmarks = (landmarks + 0.5) * in_width\n",
    "        # convert to original axis\n",
    "        landmarks[:, 0] = landmarks[:, 0] / in_width * width\n",
    "        landmarks[:, 1] = landmarks[:, 1] / in_width * height\n",
    "        \n",
    "        return landmarks\n",
    "        \n",
    "        \n",
    "    def full_landmarks_detect(self, image_path):\n",
    "        # Load the image (np.ndarray)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Convert BGR to RGB\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect faces in the image\n",
    "        faces = self.face_detect(image_rgb, 1)\n",
    "\n",
    "        # Draw rectangles around the detected faces\n",
    "        for i, face in enumerate(faces):\n",
    "            left, top, right, bottom = (face.left(), face.top(), face.right(), face.bottom())\n",
    "            landmarks = self.landmarks_detect(image_rgb[top:bottom, left:right])\n",
    "            landmarks = landmarks + [left, top]\n",
    "            \n",
    "            cv2.rectangle(image_rgb, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "            for x, y in landmarks:\n",
    "                cv2.circle(image_rgb, (int(round(x)), int(round(y))), radius=1, color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "        # Display the image with detected faces\n",
    "        plt.imshow(image_rgb)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_pred = A.Compose([\n",
    "    A.Resize(height=224, width=224),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dlib' has no attribute 'get_frontal_face_detector'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m detector \u001b[38;5;241m=\u001b[39m \u001b[43mdlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_frontal_face_detector\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'dlib' has no attribute 'get_frontal_face_detector'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
